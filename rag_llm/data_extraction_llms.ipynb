{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --quiet langchain langchain-community langchain-openai chromadb \n",
    "!pip3 install --upgrade --quiet pypdf pandas streamlit python-dotenv\n",
    "!pip3 install --upgrade --quiet transformers sentence-transformers langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Import Langchain modules\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Other modules and packages\n",
    "import os\n",
    "import tempfile\n",
    "import streamlit as st  \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model='llama3.1:8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...Neil Armstrong!\\n\\nOn July 20, 1969, Neil Armstrong became the first person to set foot on the lunar surface during the Apollo 11 mission. As he stepped off the lunar module Eagle and onto the moon\\'s surface, he famously declared:\\n\\n\"That\\'s one small step for man, one giant leap for mankind.\"\\n\\nWould you like to know more about his historic achievement?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm.invoke(\"The first man on the moon was ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# import sys\n",
    "# path = sys.path[1]+'/myenv'  #try .path[0] if 1 doesn't work\n",
    "# load_dotenv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Company_Profile.pdf', 'page': 0}, page_content='INSIGHT\\nCOMPANY BROCHURENISE\\n+03 5635 3248\\nwww.nise.com\\nsupport@nise.my'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 1}, page_content='About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesAbout Us\\nRecognizing the crucial role of skills and knowledge in\\nsustaining business solutions, our commitment begins\\nwith offering extensive training services.\\nSpecializing in MicroStrategy, NiSE Insight is powered by\\na team with of business intelligence experience\\nspanning two decades.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n4 32 1Established in\\nOctober 2017Local \\nServices Provider\\n100%\\nBumiputra95% \\nTechnical Team'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 2}, page_content='About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesOur Offering+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\nProfessional Services BI Resources\\n#CONSULTATION\\n- Business Framework \\n- BI Methodology \\n- Data Governance\\n- Implementation Strategy\\n- Technical Advisory\\n#DEVELOPMENT\\n- End to End BI Implementation \\n- Turnkey Project \\n- Joint Implementation'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 3}, page_content='BI Resources Professional Services\\nMinimum Contract 1 Year\\nData Governance\\nOn-Site & Off-Site Engagement01\\n02\\n03About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesOur Offering+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 4}, page_content='CUSTOMISED TRAINING & WORKSHOPAbout Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesNiSE Academy\\nWe provide education programs that include\\nclassroom & online, customized training and workshop\\nspecifically for Business Intelligence, ETL and Data\\nWarehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n01BOOTCAMP\\nBootcamp comprises of mix and match modules to\\ncater three different groups for Beginners,\\nIntermediate and Advanced Users. \\nIt combines several modules into 5-Days training to\\nenable beginners to explore and be able to do their\\nown project.\\nWe provide customised training based on\\ncustomerʼs data and environment. This hands-on\\ntraining could give more insight and\\nunderstandable of your business requirement. 02'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 5}, page_content='CUSTOMISED TRAINING & WORKSHOPAbout Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesNiSE Academy\\nWe provide education programs that include\\nclassroom & online, customized training and workshop\\nspecifically for Business Intelligence, ETL and Data\\nWarehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n01PRODUCT TRAINING\\nDynamic training program meticulously crafted to\\ncater to individuals at every skill level. Our innovative\\napproach consolidates various modules,\\ncondensing them into a power-packed 5-day\\ntraining session, unleashing the potential of a\\nbeginner to independently embark on your projects\\nwith confidence.\\nDiscover the power of tailored training designed\\nspecifically that aligns with your unique data and\\nenvironment. Our hands-on approach unlocks\\nprofound insights, making your business\\nrequirements not just understandable but utterly\\ncompelling.02'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 6}, page_content='CUSTOMISED TRAINING & WORKSHOPAbout Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesNiSE Academy\\nWe provide education programs that include\\nclassroom & online, customized training and workshop\\nspecifically for Business Intelligence, ETL and Data\\nWarehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n03TECHNICAL TRAINING\\nOur technical training caters specifically to\\nAdministrators and Database Administrators,\\nequipping them to proficiently design and maintain\\ndatabase enterprise assets. This encompasses\\noptimizing database performance based on query\\ntypes, usage patterns, and application design\\nrequirements. Our comprehensive training also\\ndelves into configuration, security maintenance,\\nsystem usage monitoring, architecture optimization,\\nerror reduction, maximizing uptime, and boost\\nperformance\\nOur certification program provides both\\nspecialized certificates related to product tools\\nand general skills certifications, issued by both the\\nPrincipal and Third-Party training providers04'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 7}, page_content=\"Fuel the success of your project with our essential on-site\\nsupport and maintenance services. We don't just keep\\nthings running smoothly; we pave the way for the\\ncontinuous growth of your vital data infrastructure.\\nIn the dynamic world of data warehousing and business\\nintelligence, our on-site support and maintenance go\\nbeyond services—they're the guardians of your project's\\nsuccess. Set your expectations high; choose excellence;\\nchoose us.About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesMaintenance & Support Services+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\nOnsite-Support &  \\nMaintenance Services\\nSoftware\\nCorrective\\nMaintenance\\nTechnical\\nConsultation \\nTechnical\\nSupport\\nHealth\\nCheck\\nPreventive\\nMaintenance\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"Company_Profile.pdf\")\n",
    "pages = loader.load()\n",
    "pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=350,\n",
    "                                            chunk_overlap=100,\n",
    "                                            length_function=len,\n",
    "                                            separators=[\"\\n\\n\", \"\\n\", \" \"])\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Company_Profile.pdf', 'page': 0}, page_content='INSIGHT\\nCOMPANY BROCHURENISE\\n+03 5635 3248\\nwww.nise.com\\nsupport@nise.my'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 1}, page_content='About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesAbout Us\\nRecognizing the crucial role of skills and knowledge in\\nsustaining business solutions, our commitment begins\\nwith offering extensive training services.\\nSpecializing in MicroStrategy, NiSE Insight is powered by\\na team with of business intelligence experience'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 1}, page_content='a team with of business intelligence experience\\nspanning two decades.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n4 32 1Established in\\nOctober 2017Local \\nServices Provider\\n100%\\nBumiputra95% \\nTechnical Team'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 2}, page_content='About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesOur Offering+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\nProfessional Services BI Resources\\n#CONSULTATION\\n- Business Framework \\n- BI Methodology \\n- Data Governance'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 2}, page_content='#CONSULTATION\\n- Business Framework \\n- BI Methodology \\n- Data Governance\\n- Implementation Strategy\\n- Technical Advisory\\n#DEVELOPMENT\\n- End to End BI Implementation \\n- Turnkey Project \\n- Joint Implementation'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 3}, page_content='BI Resources Professional Services\\nMinimum Contract 1 Year\\nData Governance\\nOn-Site & Off-Site Engagement01\\n02\\n03About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesOur Offering+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 3}, page_content='support@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 4}, page_content='CUSTOMISED TRAINING & WORKSHOPAbout Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesNiSE Academy\\nWe provide education programs that include\\nclassroom & online, customized training and workshop\\nspecifically for Business Intelligence, ETL and Data\\nWarehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 4}, page_content='Warehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n01BOOTCAMP\\nBootcamp comprises of mix and match modules to\\ncater three different groups for Beginners,\\nIntermediate and Advanced Users.'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 4}, page_content='cater three different groups for Beginners,\\nIntermediate and Advanced Users. \\nIt combines several modules into 5-Days training to\\nenable beginners to explore and be able to do their\\nown project.\\nWe provide customised training based on\\ncustomerʼs data and environment. This hands-on\\ntraining could give more insight and'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 4}, page_content='customerʼs data and environment. This hands-on\\ntraining could give more insight and\\nunderstandable of your business requirement. 02'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 5}, page_content='CUSTOMISED TRAINING & WORKSHOPAbout Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesNiSE Academy\\nWe provide education programs that include\\nclassroom & online, customized training and workshop\\nspecifically for Business Intelligence, ETL and Data\\nWarehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 5}, page_content='Warehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n01PRODUCT TRAINING\\nDynamic training program meticulously crafted to\\ncater to individuals at every skill level. Our innovative\\napproach consolidates various modules,'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 5}, page_content='cater to individuals at every skill level. Our innovative\\napproach consolidates various modules,\\ncondensing them into a power-packed 5-day\\ntraining session, unleashing the potential of a\\nbeginner to independently embark on your projects\\nwith confidence.\\nDiscover the power of tailored training designed'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 5}, page_content='with confidence.\\nDiscover the power of tailored training designed\\nspecifically that aligns with your unique data and\\nenvironment. Our hands-on approach unlocks\\nprofound insights, making your business\\nrequirements not just understandable but utterly\\ncompelling.02'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 6}, page_content='CUSTOMISED TRAINING & WORKSHOPAbout Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesNiSE Academy\\nWe provide education programs that include\\nclassroom & online, customized training and workshop\\nspecifically for Business Intelligence, ETL and Data\\nWarehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 6}, page_content='Warehousing.+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\n03TECHNICAL TRAINING\\nOur technical training caters specifically to\\nAdministrators and Database Administrators,\\nequipping them to proficiently design and maintain'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 6}, page_content='Administrators and Database Administrators,\\nequipping them to proficiently design and maintain\\ndatabase enterprise assets. This encompasses\\noptimizing database performance based on query\\ntypes, usage patterns, and application design\\nrequirements. Our comprehensive training also\\ndelves into configuration, security maintenance,'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 6}, page_content='requirements. Our comprehensive training also\\ndelves into configuration, security maintenance,\\nsystem usage monitoring, architecture optimization,\\nerror reduction, maximizing uptime, and boost\\nperformance\\nOur certification program provides both\\nspecialized certificates related to product tools\\nand general skills certifications, issued by both the'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 6}, page_content='and general skills certifications, issued by both the\\nPrincipal and Third-Party training providers04'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 7}, page_content=\"Fuel the success of your project with our essential on-site\\nsupport and maintenance services. We don't just keep\\nthings running smoothly; we pave the way for the\\ncontinuous growth of your vital data infrastructure.\\nIn the dynamic world of data warehousing and business\\nintelligence, our on-site support and maintenance go\"),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 7}, page_content=\"intelligence, our on-site support and maintenance go\\nbeyond services—they're the guardians of your project's\\nsuccess. Set your expectations high; choose excellence;\\nchoose us.About Us\\nNiSE\\nAcademyOur Offering\\nMaintenance\\n& Support\\nServicesMaintenance & Support Services+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\"),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 7}, page_content='& Support\\nServicesMaintenance & Support Services+03 5635 3248\\nwww.nise.com\\nsupport@nise.my\\nA-05-29, Sunway Geo Avenue, Jalan Lagoon\\nSelatan, Sunway South Quay, Bandar Sunway,\\n47500 Subang Jaya, Selangor Darul Ehsan\\nOnsite-Support &  \\nMaintenance Services\\nSoftware\\nCorrective\\nMaintenance\\nTechnical\\nConsultation \\nTechnical\\nSupport\\nHealth\\nCheck'),\n",
       " Document(metadata={'source': 'Company_Profile.pdf', 'page': 7}, page_content='Software\\nCorrective\\nMaintenance\\nTechnical\\nConsultation \\nTechnical\\nSupport\\nHealth\\nCheck\\nPreventive\\nMaintenance')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "def get_embedding_function():\n",
    "    embeddings = OllamaEmbeddings(model=\"llama3.1:8b\")\n",
    "    return embeddings\n",
    "\n",
    "embedding_function = get_embedding_function()\n",
    "\n",
    "# llm = Ollama(model='llama3.1:8b')\n",
    " \n",
    "# vectorstoredb = FAISS.load_local(faiss_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    " \n",
    "# retriever = vectorstoredb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(evaluator=\"embedding_distance\", \n",
    "                            embeddings=embedding_function)\n",
    "\n",
    "# evaluator.evaluate_strings(prediction=\"Amsterdam\", reference=\"coffeeshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.42799206948277213}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluator.evaluate_strings(prediction=\"Paris\", reference=\"coffeeshop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Create a list of unique ids for each document based on the content\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    # Ensure that only unique docs with unique ids are kept\n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = [] \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    # Create a new Chroma database from the documents\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        persist_directory = vectorstore_path)\n",
    "\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference API HTTP code: 500, {\"error\":\"model requires more system memory (5.9 GiB) than is available (5.5 GiB)\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create vectorstore\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mvectorstore_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvectorstore_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 19\u001b[0m, in \u001b[0;36mcreate_vectorstore\u001b[1;34m(chunks, embedding_function, vectorstore_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m         unique_chunks\u001b[38;5;241m.\u001b[39mappend(chunk) \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Create a new Chroma database from the documents\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvectorstore_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39mpersist()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n",
      "File \u001b[1;32mc:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:878\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    876\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    877\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:842\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    836\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[0;32m    837\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[0;32m    838\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    839\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    840\u001b[0m         )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 842\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[1;32mc:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:208\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed documents using an Ollama deployed embedding model.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m--> 208\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:196\u001b[0m, in \u001b[0;36mOllamaEmbeddings._embed\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_emb_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[1;32mc:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:170\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference API HTTP code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;241m%\u001b[39m (res\u001b[38;5;241m.\u001b[39mstatus_code, res\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     t \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mValueError\u001b[0m: Error raised by inference API HTTP code: 500, {\"error\":\"model requires more system memory (5.9 GiB) than is available (5.5 GiB)\"}"
     ]
    }
   ],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = create_vectorstore(chunks=chunks, \n",
    "                                 embedding_function=embedding_function, \n",
    "                                 vectorstore_path=\"vectorstore_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorstore\n",
    "vectorstore = Chroma(persist_directory=\"vectorstore_test\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'source': 'Remittance - 50-CR002539GT4PAY070322-339.pdf'}, page_content='SOCSO - Employee 28/02/22 -19.75 -19.75 MYR\\nMalaysia Income Tax 28/02/22 -20.80 -20.80 MYR'),\n",
       " Document(metadata={'page': 0, 'source': 'Remittance - 50-CR002539GT4PAY070322-339.pdf'}, page_content='EPF - Employee 28/02/22 -333.00 -333.00 MYR\\nSOCSO - Employee 28/02/22 -19.75 -19.75 MYR'),\n",
       " Document(metadata={'page': 0, 'source': 'Remittance - 50-CR002539GT4PAY070322-339.pdf'}, page_content='Malaysia Income Tax 28/02/22 -20.80 -20.80 MYR\\n4,012.45 Payment Due MYR'),\n",
       " Document(metadata={'page': 0, 'source': 'Remittance - 50-CR002539GT4PAY070322-339.pdf'}, page_content='EIS - Employee 28/02/22 -7.90 -7.90 MYR\\nEPF - Employee 28/02/22 -333.00 -333.00 MYR')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create retriever and get relevant chunks\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "relevant_chunks = retriever.invoke(\"How much was the employee EPF contribution in MYR?\")\n",
    "relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. DON'T MAKE UP ANYTHING.\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "You are an assistant for question-answering tasks.\n",
      "Use the following pieces of retrieved context to answer\n",
      "the question. If you don't know the answer, say that you\n",
      "don't know. DON'T MAKE UP ANYTHING.\n",
      "\n",
      "SOCSO - Employee 28/02/22 -19.75 -19.75 MYR\n",
      "Malaysia Income Tax 28/02/22 -20.80 -20.80 MYR\n",
      "\n",
      "---\n",
      "\n",
      "EPF - Employee 28/02/22 -333.00 -333.00 MYR\n",
      "SOCSO - Employee 28/02/22 -19.75 -19.75 MYR\n",
      "\n",
      "---\n",
      "\n",
      "Malaysia Income Tax 28/02/22 -20.80 -20.80 MYR\n",
      "4,012.45 Payment Due MYR\n",
      "\n",
      "---\n",
      "\n",
      "EIS - Employee 28/02/22 -7.90 -7.90 MYR\n",
      "EPF - Employee 28/02/22 -333.00 -333.00 MYR\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: How much was the employee EPF contribution in MYR?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate context text\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "# Create prompt\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, \n",
    "                                question=\"How much was the employee EPF contribution in MYR?\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the retrieved context, the employee's EPF contribution is -333.00 MYR.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unfortunately, I don\\'t have that information in the provided context. The names of the individuals are not mentioned. However, I can tell you that the date concerned is 28/02/22. As for the total pay, it\\'s difficult to determine without knowing which specific transactions (e.g., EPF, SOCSO, EIS) belong to this individual.\\n\\nThe only transaction related directly to an \"Employee\" is for EIS and SOCSO on 28/02/22, with a total of -19.75 MYR.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm\n",
    "        )\n",
    "# rag_chain.invoke(\"What date was the EPF deduction made?\")\n",
    "rag_chain.invoke(\"Give me the name on the remittance, total pay, date of pay and the number of overtime hours the individual worked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithSources(BaseModel):\n",
    "    \"\"\"An answer to the question, with sources and reasoning.\"\"\"\n",
    "    answer: str = Field(description=\"Answer to question\")\n",
    "    sources: str = Field(description=\"Full direct text chunk from the context used to answer the question\")\n",
    "    reasoning: str = Field(description=\"Explain the reasoning of the answer based on the sources\")\n",
    "\n",
    "class ExtractedInfo(BaseModel):\n",
    "    \"\"\"Extracted information about the payslip\"\"\"\n",
    "    name: AnswerWithSources\n",
    "    total_pay: AnswerWithSources\n",
    "    date: AnswerWithSources\n",
    "    overtime: AnswerWithSources\n",
    "\n",
    "# class ExtractedInfo(BaseModel):\n",
    "#     \"\"\"Extracted information about the research article\"\"\"\n",
    "#     paper_title: AnswerWithSources\n",
    "#     paper_summary: AnswerWithSources\n",
    "#     publication_year: AnswerWithSources\n",
    "#     paper_authors: AnswerWithSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ollama' object has no attribute 'as_structured_llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      2\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: retriever \u001b[38;5;241m|\u001b[39m format_docs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()}\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;241m|\u001b[39m prompt_template\n\u001b[1;32m----> 4\u001b[0m             \u001b[38;5;241m|\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_structured_llm\u001b[49m(output_cls\u001b[38;5;241m=\u001b[39mExtractedInfo)\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;66;03m# | llm.with_structured_output(ExtractedInfo, strict=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         )\n\u001b[0;32m      8\u001b[0m rag_chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me the name on the remittance, total pay, date of pay and the number of overtime hours the individual worked.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\RivyeschRanjan\\Desktop\\Research\\rag_llm\\myenv\\Lib\\site-packages\\pydantic\\main.py:856\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Ollama' object has no attribute 'as_structured_llm'"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm.as_structured_llm(output_cls=ExtractedInfo)\n",
    "            # | llm.with_structured_output(ExtractedInfo, strict=True)\n",
    "        )\n",
    "\n",
    "rag_chain.invoke(\"Give me the name on the remittance, total pay, date of pay and the number of overtime hours the individual worked.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
